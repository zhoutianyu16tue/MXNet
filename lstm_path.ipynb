{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "def Perplexity(label, pred):\n",
    "    \"\"\" Calculates prediction perplexity\n",
    "    Args:\n",
    "        label (mx.nd.array): labels array\n",
    "        pred (mx.nd.array): prediction array\n",
    "    Returns:\n",
    "        float: calculated perplexity\n",
    "    \"\"\"\n",
    "    # collapse the time, batch dimension\n",
    "    label = label.reshape((-1,))\n",
    "    pred = pred.reshape((-1, pred.shape[-1]))\n",
    "\n",
    "    loss = 0.\n",
    "    for i in range(pred.shape[0]):\n",
    "        loss += -np.log(max(1e-10, pred[i][int(label[i])]))\n",
    "    return np.exp(loss / label.size)\n",
    "\n",
    "def default_read_content(path):\n",
    "    with open(path) as ins:\n",
    "        return ins.read()[:-1]\n",
    "\n",
    "def default_build_vocab(path):\n",
    "    content = default_read_content(path)\n",
    "    content = content.replace('\\n', ',').split(',')\n",
    "    return map(lambda d: int(d), set(content))\n",
    "\n",
    "def build_paths(path, buckets):\n",
    "    content = default_read_content(path)\n",
    "    paths = content.split('\\n')\n",
    "    data = []\n",
    "    \n",
    "    for path in paths:\n",
    "        path = map(lambda d: int(d), path.split(','))\n",
    "\n",
    "        if len(path) == 0:\n",
    "            continue\n",
    "        \n",
    "        data.append(path)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "buckets = [11, 21, 31, 41]\n",
    "num_hidden = 200\n",
    "num_embed = 200\n",
    "num_layers = 2\n",
    "\n",
    "num_epoch = 20\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "invalid_label = 0\n",
    "\n",
    "# Update count per available GPUs\n",
    "gpu_count = 1\n",
    "contexts = [mx.context.gpu(i) for i in range(gpu_count)]\n",
    "# contexts = mx.cpu()\n",
    "vocab = default_build_vocab(os.path.join(data_dir, 'path_train.txt'))\n",
    "vocab.append(0)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = build_paths(os.path.join(data_dir, 'path_train.txt'), buckets)\n",
    "val_paths = build_paths(os.path.join(data_dir, 'path_val.txt'), buckets)\n",
    "test_paths = build_paths(os.path.join(data_dir, 'path_test.txt'), buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: discarded 0 sentences longer than the largest bucket.\n",
      "WARNING: discarded 0 sentences longer than the largest bucket.\n"
     ]
    }
   ],
   "source": [
    "data_train  = mx.rnn.BucketSentenceIter(train_paths, batch_size, buckets=buckets,\n",
    "                                            invalid_label=invalid_label)\n",
    "data_val    = mx.rnn.BucketSentenceIter(val_paths, batch_size, buckets=buckets,\n",
    "                                            invalid_label=invalid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = mx.rnn.SequentialRNNCell()\n",
    "\n",
    "for i in range(num_layers):\n",
    "    stack.add(mx.rnn.LSTMCell(num_hidden=num_hidden, prefix='lstm_l%d_'%i))\n",
    "\n",
    "def sym_gen(seq_len):\n",
    "    data = mx.sym.Variable('data')\n",
    "    label = mx.sym.Variable('softmax_label')\n",
    "    embed = mx.sym.Embedding(data=data, input_dim=len(vocab),\n",
    "                             output_dim=num_embed, name='embed')\n",
    "\n",
    "    stack.reset()\n",
    "    outputs, states = stack.unroll(seq_len, inputs=embed, merge_outputs=True)\n",
    "\n",
    "    pred = mx.sym.Reshape(outputs, shape=(-1, num_hidden))\n",
    "    pred = mx.sym.FullyConnected(data=pred, num_hidden=len(vocab), name='pred')\n",
    "\n",
    "    label = mx.sym.Reshape(label, shape=(-1,))\n",
    "    pred = mx.sym.SoftmaxOutput(data=pred, label=label, name='softmax')\n",
    "\n",
    "    return pred, ('data',), ('softmax_label',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.default_bucket_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_count = 1\n",
    "contexts = [mx.context.gpu(i) for i in range(gpu_count)]\n",
    "\n",
    "model = mx.mod.BucketingModule(\n",
    "        sym_gen             = sym_gen,\n",
    "        default_bucket_key  = data_train.default_bucket_key,\n",
    "        context             = contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "# TODO: add epoch_end_callback\n",
    "\n",
    "model.fit(\n",
    "    train_data          = data_train,\n",
    "    eval_data           = data_val,\n",
    "    eval_metric         = mx.metric.np(Perplexity),\n",
    "    optimizer           = 'sgd',\n",
    "    optimizer_params    = { 'learning_rate': 0.01,\n",
    "                            'momentum': 0.9,\n",
    "                            'wd': 0.00001 },\n",
    "    initializer         = mx.init.Xavier(factor_type=\"in\", magnitude=2.34),\n",
    "    num_epoch           = 2,\n",
    "    batch_end_callback  = mx.callback.Speedometer(batch_size, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[122, 9]]\n",
    "dataiter = mx.io.NDArrayIter(data, None, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "Invalid Parameter format for num_outputs expect int but value='None', in operator SliceChannel(name=\"\", squeeze_axis=\"1\", axis=\"1\", num_outputs=\"None\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-885aa3a2f44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mxnet/python/mxnet/module/base_module.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, eval_data, num_batch, merge_batches, reset, always_output_list)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnbatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/module/bucketing_module.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data_batch, is_train)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinded\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         self.switch_bucket(data_batch.bucket_key, data_batch.provide_data,\n\u001b[0;32m--> 438\u001b[0;31m                            data_batch.provide_label)\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/module/bucketing_module.pyc\u001b[0m in \u001b[0;36mswitch_bucket\u001b[0;34m(self, bucket_key, data_shapes, label_shapes)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'call bind before switching bucket'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbucket_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buckets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sym_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             module = Module(symbol, data_names, label_names,\n\u001b[1;32m    363\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c9de8fd61846>\u001b[0m in \u001b[0;36msym_gen\u001b[0;34m(seq_len)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/rnn/rnn_cell.pyc\u001b[0m in \u001b[0;36munroll\u001b[0;34m(self, length, inputs, begin_state, layout, merge_outputs)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             inputs, states = cell.unroll(length, inputs=inputs, begin_state=states, layout=layout,\n\u001b[0;32m--> 821\u001b[0;31m                                          merge_outputs=None if i < num_cells-1 else merge_outputs)\n\u001b[0m\u001b[1;32m    822\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/rnn/rnn_cell.pyc\u001b[0m in \u001b[0;36munroll\u001b[0;34m(self, length, inputs, begin_state, layout, merge_outputs)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbegin_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mbegin_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/rnn/rnn_cell.pyc\u001b[0m in \u001b[0;36m_normalize_sequence\u001b[0;34m(length, inputs, layout, merge, in_layout)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;34m\"to list with list(inputs) first or let unroll handle splitting.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             inputs = list(symbol.split(inputs, axis=in_axis, num_outputs=length,\n\u001b[0;32m---> 64\u001b[0;31m                                        squeeze_axis=1))\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/symbol/register.pyc\u001b[0m in \u001b[0;36msplit\u001b[0;34m(data, num_outputs, axis, squeeze_axis, name, attr, out, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/_ctypes/symbol.pyc\u001b[0m in \u001b[0;36m_symbol_creator\u001b[0;34m(handle, args, kwargs, keys, vals, name)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         ctypes.byref(sym_handle)))\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mxnet/python/mxnet/base.pyc\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Invalid Parameter format for num_outputs expect int but value='None', in operator SliceChannel(name=\"\", squeeze_axis=\"1\", axis=\"1\", num_outputs=\"None\")"
     ]
    }
   ],
   "source": [
    "model.predict(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: discarded 0 sentences longer than the largest bucket.\n"
     ]
    }
   ],
   "source": [
    "data_pred = mx.rnn.BucketSentenceIter(test_paths, batch_size=batch_size, buckets=buckets,\n",
    "                                            invalid_label=invalid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = model.predict(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reshape() takes exactly 2 arguments (4 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-85d76e3c282f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: reshape() takes exactly 2 arguments (4 given)"
     ]
    }
   ],
   "source": [
    "tmp.reshape(-1, batch_size, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: discarded 0 sentences longer than the largest bucket.\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data_val    = mx.rnn.BucketSentenceIter(val_paths, batch_size, buckets=buckets,\n",
    "                                            invalid_label=invalid_label)\n",
    "\n",
    "for batch in data_val:\n",
    "    print(batch.pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_gen_buckets(sentences, batch_size):\n",
    "    len_dict = {}\n",
    "    max_len = -1\n",
    "    for sentence in sentences:\n",
    "        words = sentence\n",
    "        if len(words) == 0:\n",
    "            continue\n",
    "        if len(words) > max_len:\n",
    "            max_len = len(words)\n",
    "        if len(words) in len_dict:\n",
    "            len_dict[len(words)] += 1\n",
    "        else:\n",
    "            len_dict[len(words)] = 1\n",
    "    print(len_dict)\n",
    "\n",
    "    tl = 0\n",
    "    buckets = []\n",
    "    for l, n in len_dict.items(): # TODO: There are better heuristic ways to do this\n",
    "        if n + tl >= batch_size:\n",
    "            buckets.append(l)\n",
    "            tl = 0\n",
    "        else:\n",
    "            tl += n\n",
    "    if tl > 0:\n",
    "        buckets.append(max_len)\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 33, 3: 59, 4: 65, 5: 76, 6: 75, 7: 119, 8: 140, 9: 167, 10: 143, 11: 162, 12: 153, 13: 171, 14: 173, 15: 151, 16: 152, 17: 160, 18: 117, 19: 107, 20: 89, 21: 88, 22: 88, 23: 76, 24: 58, 25: 47, 26: 40, 27: 24, 28: 31, 29: 19, 30: 17, 31: 17, 32: 8, 33: 5, 34: 7, 35: 2, 36: 1, 37: 3, 38: 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 28,\n",
       " 30,\n",
       " 34,\n",
       " 38]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_gen_buckets(val_paths, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
